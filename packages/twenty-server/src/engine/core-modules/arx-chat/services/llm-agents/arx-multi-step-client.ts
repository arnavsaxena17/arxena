import OpenAI from 'openai';
import * as allDataObjects from '../data-model-objects';
const modelName = 'gpt-4o';
import { ToolsForAgents } from '../../services/llm-agents/prompting-tool-calling';
import { ChatCompletionMessage } from 'openai/resources';
import CandidateEngagementArx from '../../services/candidate-engagement/check-candidate-engagement';
import { WhatsappAPISelector } from '../../services/whatsapp-api/whatsapp-controls';
import Anthropic from '@anthropic-ai/sdk';

export class OpenAIArxMultiStepClient {
  personNode: allDataObjects.PersonNode;
  openAIclient: OpenAI;
  anthropic: Anthropic;
  constructor(personNode: allDataObjects.PersonNode) {
    this.openAIclient = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
    this.personNode = personNode;
    this.anthropic = new Anthropic({
      apiKey: process.env['ANTHROPIC_API_KEY'], 
    });
  }
  // THis is the entry point
  async createCompletion(mostRecentMessageArr: allDataObjects.ChatHistoryItem[],chatControl:allDataObjects.chatControls, isChatEnabled: boolean = true) {
    mostRecentMessageArr = await this.runAgentAlongWithToolCalls(mostRecentMessageArr, chatControl, isChatEnabled);
    console.log('After running the stage and candidate facing agents, the mostRecentMessageArr is::', mostRecentMessageArr);
    return mostRecentMessageArr;
  }
  async checkIfResponseMessageSoundsHumanLike(responseMessage:{content:string|null}){
    let responseMessageType :string = "seemsHumanMessage"
    try{
      console.log("Going to check if response message sounds human like or not")
      console.log("the response message is actually:", responseMessage?.content)
      if (responseMessage?.content != null && responseMessage?.content != "" ){
        const checkBotTypeMessages = [{ role: 'system', content: "Does the sentence below seem like it has been generated by a llm? If the sentence has words wrapped between asterisks ** for bold or has words like I am updating your profile or has words in square brackets like [share_jd], then it is generated by a bot and return 'yes'.  return only either 'yes' or 'no'. Return in the json format of  {'isLikeBot':'no'}. No explanation necessary" }, {role:'user', content:responseMessage.content}];
        // @ts-ignore
        const response = await this.openAIclient.chat.completions.create({ model: modelName, messages: checkBotTypeMessages, response_format:{ type: "json_object" }, });
        const LLMMessage:string =  response.choices[0].message.content || ""
        console.log("The BOT MESSAGE SOUNDS like ::::",response.choices[0].message.content)
        if (LLMMessage==="" ){
          responseMessageType = "seemsHumanMessage"
        }else{
          const isLikeBot = JSON.parse(LLMMessage)["isLikeBot"]
          if (isLikeBot === "no" || isLikeBot === "No" ){
            responseMessageType = "seemsHumanMessage"
          }
          else if (isLikeBot === "yes" || isLikeBot === "Yes" ){
            console.log("THe message does sound like a bot:", responseMessage.content)
            responseMessageType = "seemsBotMessage"
          }
          console.log("Check bot response yes/ no:",isLikeBot)
        }
        console.log("Finally response message type  ",responseMessageType )
      }
      else{
        console.log("REsponse message is either null or is empty string", responseMessage?.content)
        responseMessageType = "seemsHumanMessage"
      }
    }
    catch{
      console.log("responseMessage Type to check if HUman Message has been created is an error:", responseMessageType)
      responseMessageType = "seemsHumanMessage"
    }
    return responseMessageType
  }

  async getHumanLikeResponseMessageFromLLM(mostRecentMessageArr:allDataObjects.ChatHistoryItem[], tools:any){
    let responseMessage:ChatCompletionMessage
    try{
      console.log("Going to get human like response from llm")
      let response:any
      // First Attempt
      // @ts-ignore
      response = await this.openAIclient.chat.completions.create({ model: modelName, messages: mostRecentMessageArr, tools: tools, tool_choice: 'auto' });
      responseMessage = response.choices[0].message;
      console.log("This is the response: message", response.choices[0])
      if (responseMessage.content != null){
        const responseMessageType = await this.checkIfResponseMessageSoundsHumanLike(responseMessage)
        console.log("Check if this sounds like a human message 1st time:",responseMessageType)
        if (responseMessageType != "seemsHumanMessage"){
          console.log("The first time we tried this, there was a bot response in  responseMessage, so trying again second time")
          // @ts-ignore
          response = await this.openAIclient.chat.completions.create({ model: modelName, messages: mostRecentMessageArr, tools: tools, tool_choice: 'auto' });
          responseMessage = response.choices[0].message;
          const responseMessageType = await this.checkIfResponseMessageSoundsHumanLike(responseMessage)
          console.log("Check if this sounds like a human message 2nd time:",responseMessageType)
          if (responseMessageType != "seemsHumanMessage"){
            console.log("The second time we tried this, there was a bot response in responseMessage, so trying again third time")
            // @ts-ignore
            response = await this.openAIclient.chat.completions.create({ model: modelName, messages: mostRecentMessageArr, tools: tools, tool_choice: 'auto' });
            responseMessage = response.choices[0].message;
            const responseMessageType = await this.checkIfResponseMessageSoundsHumanLike(responseMessage)
            console.log("Check if this sounds like a human message 3rd time:",responseMessageType)
            if (responseMessageType != "seemsHumanMessage"){
              console.log("If the third time we tried, but its a fucking bot message so we are saying fuck this shit and send it anyway")
            }
          }
        }
        return responseMessage
      }
      else{
        console.log("Response Message is mostly null::, last two messages from llm have been ::" )
        return responseMessage
      }
    }
    catch(error){
      console.log("This is the error in getHumanLikeResponse, returning null:", error)
      return null
    }
  }
  async getMostRecentChatsByPerson(mostRecentMessageArr:allDataObjects.ChatHistoryItem[]){
    const lastThreeChats = mostRecentMessageArr.slice(-3);
    // Return the array in reverse order (most recent last)
    return lastThreeChats.reverse().map(chat => ({
      role: chat.role,
      content: chat.content
    }));
  
  }

  async runAgentAlongWithToolCalls(mostRecentMessageArr: allDataObjects.ChatHistoryItem[],  chatControl:allDataObjects.chatControls,  isChatEnabled: boolean = true ) {
    try{
      const lastFewChats = await this.getMostRecentChatsByPerson(mostRecentMessageArr)
      console.log("Going to run candidate facing agents with tool calls in and most recent message is :",lastFewChats )
      const newSystemPrompt = await new ToolsForAgents().getSystemPrompt(this.personNode);
      const updatedMostRecentMessagesBasedOnNewSystemPrompt = await this.updateMostRecentMessagesBasedOnNewSystemPrompt(mostRecentMessageArr, newSystemPrompt);
      const tools = await new ToolsForAgents().getTools();
      const responseMessage = await this.getHumanLikeResponseMessageFromLLM(updatedMostRecentMessagesBasedOnNewSystemPrompt, tools)
      console.log('BOT_MESSAGE in  :', "at::", new Date().toString(), ' ::: ' ,JSON.stringify(responseMessage));
      if (responseMessage){
        mostRecentMessageArr.push(responseMessage);
      }
      else{
        console.log("Response message from getHumanLikeResponseMessageFromLLM is null, so returning as it is")
        return mostRecentMessageArr
      }
      if (responseMessage?.tool_calls && isChatEnabled) {
        mostRecentMessageArr = await this.addResponseAndToolCallsToMessageHistory(responseMessage, mostRecentMessageArr,chatControl);
      }
      console.log("Sending message to candidate from addResponseAndToolCallsToMessageHistory_stage1", mostRecentMessageArr.slice(-1)[0].content);
      console.log("Message text in stage 1 received based on which we will decide whether to send message or not::",  mostRecentMessageArr.slice(-1)[0].content)
      await this.sendWhatsappMessageToCandidate( mostRecentMessageArr.slice(-1)[0].content || '', mostRecentMessageArr, 'runCandidateFacingAgentsAlongWithToolCalls_stage1', chatControl, isChatEnabled);
      return mostRecentMessageArr;
    }
    catch (error){
      console.log("There has been an error in runCandidateFacingAgentsAlongWithToolCalls::", error)
      return mostRecentMessageArr
    }
  }
  async addResponseAndToolCallsToMessageHistory(responseMessage: ChatCompletionMessage, mostRecentMessageArr: allDataObjects.ChatHistoryItem[],  chatControl:allDataObjects.chatControls) {
    const toolCalls = responseMessage?.tool_calls;
    console.log("We have made a total of ", toolCalls?.length, " tool calls in current chatResponseMessage")
    if (toolCalls) {
      for (const toolCall of toolCalls) {
        const functionName = toolCall.function.name;
        console.log('Function name is:', functionName);
        const availableFunctions = new ToolsForAgents().getAvailableFunctions();
        const functionToCall = availableFunctions[functionName];
        const functionArgs = JSON.parse(toolCall.function.arguments);
        const responseFromFunction = await functionToCall(functionArgs, this.personNode);
        mostRecentMessageArr.push({ tool_call_id: toolCall.id, role: 'tool', name: functionName, content: responseFromFunction });
      }
      const tools = await new ToolsForAgents().getTools();
      // @ts-ignore
      const response = await this.openAIclient.chat.completions.create({ model: modelName, messages: mostRecentMessageArr, tools: tools, tool_choice: 'auto' });
      console.log('BOT_MESSAGE in runCandidateFacingAgentsAlongWithToolCalls_stage2 :', "at::", new Date().toString(), ' ::: ' ,JSON.stringify(responseMessage));
      mostRecentMessageArr.push(response.choices[0].message);
      let firstStageMessageArr = mostRecentMessageArr.slice(-1)
      if (response?.choices[0]?.message?.tool_calls) {
        console.log('More Tool Calls inside of the addResponseAndToolCallsToMessageHistory. RECURSION Initiated:::: processorType::');
        mostRecentMessageArr = await this.addResponseAndToolCallsToMessageHistory(response.choices[0].message, mostRecentMessageArr, chatControl);
      }
      let messageArr_stage2 = mostRecentMessageArr.slice(-1)
      if ( messageArr_stage2[0].content != firstStageMessageArr[0].content) {
        console.log("Sending message to candidate from addResponseAndToolCallsToMessageHistory_stage2", messageArr_stage2);
        await this.sendWhatsappMessageToCandidate(response?.choices[0]?.message?.content || '', messageArr_stage2,'addResponseAndToolCallsToMessageHistory_stage2', chatControl);
      }
      else{
        console.log("The message we tried to send but sending is is ::", messageArr_stage2[0].content, "processorType")
      }
    }
    return mostRecentMessageArr;
  }

  async updateMostRecentMessagesBasedOnNewSystemPrompt(mostRecentMessageArr: allDataObjects.ChatHistoryItem[], newSystemPrompt: string) {
    mostRecentMessageArr[0] = { role: 'system', content: newSystemPrompt };
    return mostRecentMessageArr;
  }

  async sendWhatsappMessageToCandidate(messageText: string, mostRecentMessageArr: allDataObjects.ChatHistoryItem[], functionSource: string,chatControl:allDataObjects.chatControls, isChatEnabled?: boolean, ) {
    console.log('Called sendWhatsappMessage ToCandidate to send message via any whatsapp api::', functionSource, "message text::", messageText);
    if (mostRecentMessageArr[0].role != 'system' && mostRecentMessageArr.length==1) {
      console.log('Found a single sneaky message which is coming out:: ', messageText);
      return;
    }

    if (messageText.includes('#DONTRESPOND#') || messageText.includes('DONTRESPOND') && messageText) {
      console.log('Found a #DONTRESPOND# message, so not sending any message');
      return;
    }
    console.log("Going to create whatsaappupdatemessage obj for message text::", messageText)
    const whatappUpdateMessageObj:allDataObjects.candidateChatMessageType = await new CandidateEngagementArx().updateChatHistoryObjCreateWhatsappMessageObj('sendWhatsappMessageToCandidateMulti', this.personNode, mostRecentMessageArr);
    if (whatappUpdateMessageObj.messages[0].content?.includes('#DONTRESPOND#') || whatappUpdateMessageObj.messages[0].content?.includes('DONTRESPOND') && whatappUpdateMessageObj.messages[0].content) {
      console.log('Found a #DONTRESPOND# message, so not sending any message');
      return;
    }
    if ((!messageText || messageText == "") && (!whatappUpdateMessageObj.messages[0].content || whatappUpdateMessageObj.messages[0].content=="") ) {
      console.log('Message text is empty, so not sending any message');
      console.log('Current messageText::', messageText);
      console.log('Current whatappUpdateMessageObj.messages[0].content::', whatappUpdateMessageObj.messages[0].content);
      return;
    }
    if (whatappUpdateMessageObj.messages[0].content ||  messageText) {
      if (process.env.WHATSAPP_ENABLED === 'true' && (isChatEnabled === undefined || isChatEnabled)) {
        await new WhatsappAPISelector().sendWhatsappMessage(whatappUpdateMessageObj, this.personNode, mostRecentMessageArr, chatControl);
      } else {
        console.log('Whatsapp is not enabled, so not sending message:', whatappUpdateMessageObj.messages[0].content);
      }
    }
  }
}
