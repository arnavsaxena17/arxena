import OpenAI from 'openai';
import * as allDataObjects from '../data-model-objects';
const modelName = 'gpt-4o';
import { ToolsForAgents } from '../../services/llm-agents/prompting-tool-calling';
import { ChatCompletion, ChatCompletionMessage } from 'openai/resources';
import CandidateEngagementArx from '../../services/candidate-engagement/check-candidate-engagement';
import { WhatsappAPISelector } from '../../services/whatsapp-api/whatsapp-controls';
import Anthropic from '@anthropic-ai/sdk';

export class OpenAIArxMultiStepClient {
  personNode: allDataObjects.PersonNode;
  openAIclient: OpenAI;
  anthropic: Anthropic;
  constructor(personNode: allDataObjects.PersonNode) {
    this.openAIclient = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
    this.personNode = personNode;
    this.anthropic = new Anthropic({
      apiKey: process.env['ANTHROPIC_API_KEY'], // This is the default and can be omitted
    });
  }
  // THis is the entry point
  async createCompletion(mostRecentMessageArr: allDataObjects.ChatHistoryItem[], personNode: allDataObjects.PersonNode, engagementType: 'remind' | 'engage', isChatEnabled: boolean = true) {
    let processorType: string;
    // processorType = 'stage';
    // const stage = await this.getStageOfTheConversation(mostRecentMessageArr, engagementType, processorType);
    const stage = 'any-stage'
    console.log('This is the stage that is arrived at CURRENT STAGE::::::::', stage);
    processorType = 'candidate-facing';
    mostRecentMessageArr = await this.runCandidateFacingAgentsAlongWithToolCalls(mostRecentMessageArr, personNode, stage, processorType, isChatEnabled);
    console.log('After running the stage and candidate facing agents, the mostRecentMessageArr is::', mostRecentMessageArr);
    processorType = 'system-facing';
    // await this.runSystemFacingAgentsAlongWithToolCalls(mostRecentMessageArr, personNode, stage, processorType);
    // await this.runTimeManagementAgent(mostRecentMessageArr, personNode, stage);
    return mostRecentMessageArr;
  }
  async checkIfResponseMessageSoundsHumanLike(responseMessage:{content:string|null}){
    let responseMessageType :string = "seemsHumanMessage"
    try{
      console.log("Going to check if response message sounds human like or not")
      console.log("the response message is actually:", responseMessage?.content)
      if (responseMessage?.content != null && responseMessage?.content!="" ){
        const checkBotTypeMessages = [{ role: 'system', content: "Does the sentence below seem like it has been generated by a llm? return only either yes or no. Return in the json format of  {'isLikeBot':'no'}. No explanation necessary" }, {role:'user', content:responseMessage.content}];
        // @ts-ignore
        const response = await this.openAIclient.chat.completions.create({ model: modelName, messages: checkBotTypeMessages, response_format:{ type: "json_object" }, });
        const LLMMessage:string =  response.choices[0].message.content || ""
        console.log("The BOT MESSAGE SOUNDS like ::::",response.choices[0].message.content)
        if (LLMMessage==="" ){
          responseMessageType = "seemsHumanMessage"
        }else{
          const isLikeBot = JSON.parse(LLMMessage)["isLikeBot"]
          if (isLikeBot === "no" || isLikeBot === "No" ){
            responseMessageType = "seemsHumanMessage"
          }
          else if (isLikeBot === "yes" || isLikeBot === "Yes" ){
            console.log("THe message does sound like a bot:", responseMessage.content)
            responseMessageType = "seemsBotMessage"
          }
          console.log("Check bot response yes/ no:",isLikeBot)
        }
        console.log("Finally response message type  ",responseMessageType )
      }
      else{
        console.log("REsponse message is either null or is empty string", responseMessage?.content)
        responseMessageType = "seemsHumanMessage"
      }
    }
    catch{
      console.log("responseMessage Type to check if HUman Message has been created is an error:", responseMessageType)
      responseMessageType = "seemsHumanMessage"
    }
    return responseMessageType
  }

  async getHumanLikeResponseMessageFromLLM(mostRecentMessageArr:allDataObjects.ChatHistoryItem[], tools:any){
    let responseMessage:ChatCompletionMessage
    try{
      console.log("Going to get human like response from llm")
      let response:any
      // First Attempt
      // @ts-ignore
      response = await this.openAIclient.chat.completions.create({ model: modelName, messages: mostRecentMessageArr, tools: tools, tool_choice: 'auto' });
      responseMessage = response.choices[0].message;
      console.log("This is the response: message", response.choices[0])
      if (responseMessage.content != null){
        const responseMessageType = await this.checkIfResponseMessageSoundsHumanLike(responseMessage)
        console.log("Check if this sounds like a human message 1st time:",responseMessageType)
        if (responseMessageType != "seemsHumanMessage"){
          console.log("The first time we tried this, there was a bot response in  responseMessage, so trying again second time")
          // @ts-ignore
          response = await this.openAIclient.chat.completions.create({ model: modelName, messages: mostRecentMessageArr, tools: tools, tool_choice: 'auto' });
          responseMessage = response.choices[0].message;
          const responseMessageType = await this.checkIfResponseMessageSoundsHumanLike(responseMessage)
          console.log("Check if this sounds like a human message 2nd time:",responseMessageType)
          if (responseMessageType != "seemsHumanMessage"){
            console.log("The second time we tried this, there was a bot response in responseMessage, so trying again third time")
            // @ts-ignore
            response = await this.openAIclient.chat.completions.create({ model: modelName, messages: mostRecentMessageArr, tools: tools, tool_choice: 'auto' });
            responseMessage = response.choices[0].message;
            const responseMessageType = await this.checkIfResponseMessageSoundsHumanLike(responseMessage)
            console.log("Check if this sounds like a human message 3rd time:",responseMessageType)
            if (responseMessageType != "seemsHumanMessage"){
              console.log("If the third time we tried, but its a fucking bot message so we are saying fuck this shit and send it anyway")
            }
          }
        }
        return responseMessage
      }
      else{
        console.log("Response Message is mostly null::, last two messages from llm have been ::" )
        // mostRecentMessageArr.map(x => x.content)
        return responseMessage
      }
    }
    catch(error){
      console.log("This is the error in getHumanLikeResponse, returning null:", error)
      
      return null
    }
  }
  async getMostRecentChatsByPerson(mostRecentMessageArr:allDataObjects.ChatHistoryItem[]){
    const lastThreeChats = mostRecentMessageArr.slice(-3);
  
    // Return the array in reverse order (most recent last)
    return lastThreeChats.reverse().map(chat => ({
      role: chat.role,
      content: chat.content
    }));
  
  }

  async runCandidateFacingAgentsAlongWithToolCalls(mostRecentMessageArr: allDataObjects.ChatHistoryItem[], personNode: allDataObjects.PersonNode, stage: string, processorType: string, isChatEnabled: boolean = true) {
    try{
      const lastFewChats = await this.getMostRecentChatsByPerson(mostRecentMessageArr)
      console.log("Going to run candidate facing agents with tool calls in runCandidateFacingAgentsAlongWithToolCalls and most recent message is :",lastFewChats )
      const newSystemPrompt = await new ToolsForAgents().getCandidateFacingSystemPromptBasedOnStage(this.personNode, stage);
      const updatedMostRecentMessagesBasedOnNewSystemPrompt = await this.updateMostRecentMessagesBasedOnNewSystemPrompt(mostRecentMessageArr, newSystemPrompt);
      const tools = await new ToolsForAgents().getCandidateFacingToolsByStage(stage);
      const responseMessage = await this.getHumanLikeResponseMessageFromLLM(updatedMostRecentMessagesBasedOnNewSystemPrompt, tools)
      console.log('BOT_MESSAGE in runCandidateFacingAgentsAlongWithToolCalls_stage1 :', "at::", new Date().toString(), ' ::: ' ,JSON.stringify(responseMessage), '  Stage:::', stage, '  processorType::', processorType);
      if (responseMessage){
        mostRecentMessageArr.push(responseMessage); // extend conversation with assistant's reply
      }
      else{
        console.log("Response message from getHumanLikeResponseMessageFromLLM is null, so returning mostRecentMessageArr as it is")
        return mostRecentMessageArr
      }
      if (responseMessage?.tool_calls && isChatEnabled) {
        mostRecentMessageArr = await this.addResponseAndToolCallsToMessageHistory(responseMessage, mostRecentMessageArr, stage, processorType);
      }
      if (processorType === 'candidate-facing') {
        console.log("Sending message to candidate from addResponseAndToolCallsToMessageHistory_stage1", mostRecentMessageArr.slice(-1)[0].content);
        console.log("Message text in stage 1 received based on which we will decide whether to send message or not::", responseMessage?.content)
        await this.sendWhatsappMessageToCandidate(responseMessage?.content || '', mostRecentMessageArr, 'runCandidateFacingAgentsAlongWithToolCalls_stage1', isChatEnabled);
      }
      return mostRecentMessageArr;
    }
    catch (error){
      console.log("There has been an error in runCandidateFacingAgentsAlongWithToolCalls::", error)
      return mostRecentMessageArr
    }
  }
  async addResponseAndToolCallsToMessageHistory(responseMessage: ChatCompletionMessage, mostRecentMessageArr: allDataObjects.ChatHistoryItem[], stage: string, processorType: string) {
    const toolCalls = responseMessage?.tool_calls;
    console.log("We have made a total of ", toolCalls?.length, " tool calls in current chatResponseMessage")
    if (toolCalls) {
      for (const toolCall of toolCalls) {
        const functionName = toolCall.function.name;
        console.log('Function name is:', functionName);
        const availableFunctions = new ToolsForAgents().getAvailableFunctions();
        const functionToCall = availableFunctions[functionName];
        const functionArgs = JSON.parse(toolCall.function.arguments);
        const responseFromFunction = await functionToCall(functionArgs, this.personNode);
        mostRecentMessageArr.push({ tool_call_id: toolCall.id, role: 'tool', name: functionName, content: responseFromFunction });
      }
      const tools = await new ToolsForAgents().getCandidateFacingToolsByStage(stage);
      // @ts-ignore
      const response = await this.openAIclient.chat.completions.create({ model: modelName, messages: mostRecentMessageArr, tools: tools, tool_choice: 'auto' });
      console.log('BOT_MESSAGE in runCandidateFacingAgentsAlongWithToolCalls_stage2 :', "at::", new Date().toString(), ' ::: ' ,JSON.stringify(responseMessage), '  Stage:::', stage, '  processorType::', processorType);
      mostRecentMessageArr.push(response.choices[0].message);
      let firstStageMessageArr = mostRecentMessageArr.slice(-1)
      if (response?.choices[0]?.message?.tool_calls) {
        console.log('More Tool Calls inside of the addResponseAndToolCallsToMessageHistory. RECURSION Initiated:::: processorType::', processorType);
        mostRecentMessageArr = await this.addResponseAndToolCallsToMessageHistory(response.choices[0].message, mostRecentMessageArr, stage, processorType);
      }
      let messageArr_stage2 = mostRecentMessageArr.slice(-1)
      if ((processorType === 'candidate-facing') && messageArr_stage2[0].content != firstStageMessageArr[0].content) {
        console.log("Sending message to candidate from addResponseAndToolCallsToMessageHistory_stage2", messageArr_stage2);
        await this.sendWhatsappMessageToCandidate(response?.choices[0]?.message?.content || '', messageArr_stage2, 'addResponseAndToolCallsToMessageHistory_stage2');
      }
      else{
        console.log("Not sending message from stage 2 because its likely a duplicate:: processor is ", processorType)
        console.log("The message we tried to send but sending is is ::", messageArr_stage2[0].content)
      }
    }
    return mostRecentMessageArr;
  }


  async getStageOfTheConversation(mostRecentMessageArr: allDataObjects.ChatHistoryItem[], engagementType: 'remind' | 'engage', processorType: string) {
    let stage: string | null;
    console.log('Engagement Type::', engagementType);
    if (engagementType === 'remind') {
      console.log('Engagement type is reminder, so will try to get the stage from the last message');
      const messagesWithTimeStamp = this.personNode.candidates.edges[0].node.whatsappMessages.edges.map(edge => {
          return {
            role: edge.node.name === 'candidateMessage' ? 'user' : 'assistant',
            content: 'TimeStamp: ' + edge.node.createdAt + ' Message: ' + edge.node.message,
          };
        }).reverse();
      const checkReminderPrompt = await new ToolsForAgents().getTimeManagementPrompt(this.personNode);
      messagesWithTimeStamp.unshift({ role: 'system', content: checkReminderPrompt });
      console.log('got here to with the checkReminderPrompt prompt', checkReminderPrompt);
      // @ts-ignore
      const response = await this.openAIclient.chat.completions.create({ model: modelName, messages: messagesWithTimeStamp });
      stage = response.choices[0].message.content;
      console.log('This is the stage that is determined by the model:', stage);

      console.log('MessagesWithTimeStamp:::', messagesWithTimeStamp);
      console.log('mostRecentMessageArr::', mostRecentMessageArr);
      stage = 'remind_candidate';
      console.log('This is the stage here:', stage);
    } else {
      console.log('got here to get the stage of the conversation');
      const stagePrompt = await new ToolsForAgents().getStagePrompt();
      // console.log('got here to with the stage prompt', stagePrompt);
      const updatedMostRecentMessagesBasedOnNewSystemPrompt = await this.updateMostRecentMessagesBasedOnNewSystemPrompt(mostRecentMessageArr, stagePrompt);
      console.log('Got the updated recement messages for stage prompt:', updatedMostRecentMessagesBasedOnNewSystemPrompt);
      // @ts-ignore
      const response = await this.openAIclient.chat.completions.create({ model: modelName, messages: updatedMostRecentMessagesBasedOnNewSystemPrompt });
      console.log("This is the stage that is arrived at:::", response.choices[0].message.content)
      stage = response.choices[0].message.content ?? '1';
      console.log('This the stage that is determined by the model:', response.choices[0].message.content, '  Stage::', stage, '  processorType::', processorType);
    }
    console.log('This is the stage that is arrived at:', stage);
    return stage;
  }

  async updateMostRecentMessagesBasedOnNewSystemPrompt(mostRecentMessageArr: allDataObjects.ChatHistoryItem[], newSystemPrompt: string) {
    mostRecentMessageArr[0] = { role: 'system', content: newSystemPrompt };
    return mostRecentMessageArr;
  }

  async runSystemFacingAgentsAlongWithToolCalls(mostRecentMessageArr: allDataObjects.ChatHistoryItem[], personNode: allDataObjects.PersonNode, stage: string, processorType: string) {
    const newSystemPrompt = await new ToolsForAgents().getSystemFacingSystemPromptBasedOnStage(this.personNode, stage);
    const updatedMostRecentMessagesBasedOnNewSystemPrompt = this.updateMostRecentMessagesBasedOnNewSystemPrompt(mostRecentMessageArr, newSystemPrompt);
    const tools = await new ToolsForAgents().getSystemFacingToolsByStage(stage);
    // @ts-ignore
    const response = await this.openAIclient.chat.completions.create({ model: modelName, messages: mostRecentMessageArr, tools: tools, tool_choice: 'auto' });
    const responseMessage: ChatCompletionMessage = response.choices[0].message;
    console.log(new Date().toString(), ' : ', 'BOT_MESSAGE in runSystemFacingAgentsAlongWithToolCalls:::', JSON.stringify(responseMessage), '  Stage::', stage, 'processorType::', processorType);
    mostRecentMessageArr.push(responseMessage); // extend conversation with assistant's reply
    if (responseMessage?.tool_calls) {
      mostRecentMessageArr = await this.addResponseAndToolCallsToMessageHistory(responseMessage, mostRecentMessageArr, stage, processorType);
    }
  }


  async sendWhatsappMessageToCandidate(messageText: string, mostRecentMessageArr: allDataObjects.ChatHistoryItem[], functionSource: string, isChatEnabled?: boolean) {
    console.log('Called sendWhatsappMessageToCandidate to send message via any whatsapp api::', functionSource, "message text::", messageText);
    if (messageText.includes('#DONTRESPOND#') || messageText.includes('DONTRESPOND') && messageText) {
      console.log('Found a #DONTRESPOND# message, so not sending any message');
      return;
    }
    if (!messageText || messageText == "") {
      console.log('Message text is empty, so not sending any message');
      return;
    }
    console.log("Going to create whatsaappupdatemessage obj for message text::", messageText)
    const whatappUpdateMessageObj = await new CandidateEngagementArx().updateChatHistoryObjCreateWhatsappMessageObj('sendWhatsappMessageToCandidateMulti', this.personNode, mostRecentMessageArr);
    if (whatappUpdateMessageObj.messages[0].content?.includes('#DONTRESPOND#') || whatappUpdateMessageObj.messages[0].content?.includes('DONTRESPOND') && whatappUpdateMessageObj.messages[0].content) {
      console.log('Found a #DONTRESPOND# message, so not sending any message');
      return;
    }
    if (!whatappUpdateMessageObj.messages[0].content || whatappUpdateMessageObj.messages[0].content == "") {
      console.log('Message text is empty, so not sending any message');
      return;
    }
    if (whatappUpdateMessageObj.messages[0].content ) {
      if (process.env.WHATSAPP_ENABLED === 'true' && (isChatEnabled === undefined || isChatEnabled)) {
        await new WhatsappAPISelector().sendWhatsappMessage(whatappUpdateMessageObj, this.personNode, mostRecentMessageArr);
      } else {
        console.log('Whatsapp is not enabled, so not sending message:', whatappUpdateMessageObj.messages[0].content);
      }
    }
  }

  // async runTimeManagementAgent(mostRecentMessageArr: allDataObjects.ChatHistoryItem[], personNode: allDataObjects.PersonNode, stage: string) {
  //   const timeManagementPrompt = await new ToolsForAgents().getTimeManagementPrompt(personNode, stage);
  //   let updatedMostRecentMessagesBasedOnNewSystemPrompt = await this.updateMostRecentMessagesBasedOnNewSystemPrompt(mostRecentMessageArr, timeManagementPrompt);
  //   const timeManagementTool = new ToolsForAgents().getTimeManagementTools();
  //   // @ts-ignore
  //   const response = await this.openAIclient.chat.completions.create({ model: modelName, messages: updatedMostRecentMessagesBasedOnNewSystemPrompt, tools: timeManagementTool, tool_choice: "auto", });
  //   const responseMessage: ChatCompletionMessage = response.choices[0].message;
  //   console.log("BOT_MESSAGE:", responseMessage.content);
  //   updatedMostRecentMessagesBasedOnNewSystemPrompt.push(responseMessage); // extend conversation with assistant's reply
  //   if (responseMessage.tool_calls) {
  //     updatedMostRecentMessagesBasedOnNewSystemPrompt = await this.addResponseAndToolCallsToMessageHistory(responseMessage, updatedMostRecentMessagesBasedOnNewSystemPrompt, stage);
  //   }
  // }
}
